# Домашнее задание к занятию 10.6 «Инцидент-менеджмент»

## Основная часть

Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

Информация о сбое: 

* [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/);
* [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).


---

### Постмортем

- Краткое описание инцидента
    - В ходе выполнения работ по замене сетевого оборудования была кратковременно потеряна связность между региональными датацентрами интернет-ресурса github.com. Это вызвало цепочку событий, которые привели к существенному ухудшению качества работы интернет-ресурса на 24 часа 11 минут. В ходе инцидента произошло нарушение целостности и консистентности данных в репликах MySQL, а также возникли проблемы в работе некоторых других сервисов. Для ускорения восстановления работы интернет-ресурса были принудительно выключены сервисы notification, pushes и build pages. Во время восстановления предпочтение отдавалось сохранению целостности уже имеющихся данных, а не удобству использования интернет-ресурса.

- Предшествующие события
    - Проведение регламентных работ по замене вышедшего из строя оптического сетевого оборудования в 22:52 UTC 21-10-18.

- Причина инцидента
    - Разрыв соединения на 43 сек. между сетевым концентратором на восточном побережье США и основным центром обработки данных на восточном побережье США, который привел к неконсистентности в репликах базы данных MySQL.

- Воздействие
    - В большинстве случаев интернет-ресурс github.com не мог обслуживать события веб-перехватчиков (webhooks) или создавать и публиковать сайты в сервисе GitHub Pages.

- Обнаружение
    - В 22:54 внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в системах интернет-ресурса. В 23:02 инженеры группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии. 

- Реакция
    - В 23:09 команда поддержки присвоила инциденту желтый статус. Отправлено предупреждение координатору инцидентов. 
    - В 23:11 к команде поддержки присоединился координатор инцидентов и изменил статус инцидента на красный. Были вызваны дополнительные инженеры из группы разработки баз данных GitHub.

- Восстановление
    - Восстановление баз данных из резервных копий;
    - Синхронизация реплик баз данных между центрами обработки данных;
    - Возвращение к стабильной топологии обслуживания;
    - Возобновление обработки заданий в очереди;

- Таймлайн
    - 22:52 UTC 21-10-18 выполнена замена оптического оборудования. Оркестратором начато аварийное переключение кластеров для направления трафика в центр обработки данных на западном побережье США.
    - 22:54 UTC 21-10-18 внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в системах. В это время несколько инженеров работали над сортировкой входящих уведомлений. 
    - 23:02 UTC 21-10-18 инженеры группы быстрого реагирования заметили, что кластеры баз данных неконсистентны. Оркестратор показал топологию репликации базы данных, которая включала только серверы из центра обработки данных на западном побережье США.
    - 23:07 UTC 21-10-18 отвечающая команда инженеров решила вручную заблокировать внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений.
    - 23:13 UTC 21-10-18 стало понятно, что проблема затронула множество кластеров баз данных. Были вызваны дополнительные инженеры из группы разработки баз данных GitHub. Они начали исследовать текущее состояние, чтобы определить, какие действия необходимо предпринять, чтобы вручную настроить базу данных Восточного побережья США в качестве основной для каждого кластера и перестроить топологию репликации. Принято решение восстановить кластеры баз данных из резервной копии и сохранить пользовательские данные, находящиеся в очереди.
    - 23:19 UTC 21-10-18 принято решение о временном отключении части сервисов (webhooks, GitHub Pages)  для ускорения восстановления баз данных и сохранения уже полученных от пользователей данных.
    - 00:05 UTC 22-10-18 инженеры начали разработку плана по устранению несоответствий данных и внедрению новых процедур аварийного переключения для MySQL.
    - 00:41 UTC 22-10-18 инициирован процесс восстановления всех затронутых кластеров MySQL. Несколько групп инженеров искали способы ускорить передачу и время восстановления данных без дальнейшего ухудшения удобства использования сайта или риска повреждения данных.
    - 06:51 UTC 22-10-18 несколько кластеров завершили восстановление данных из резервных копий в центре обработки данных на восточном побережье США и начали репликацию новых данных с западного побережья.
    - 07:46 UTC 22-10-18 GitHub опубликовал в своем блоге Incident Report о произошедшем сбое.
    - 11:12 UTC 22-10-18 восстановление первичных баз данных завершено. Несмотря на то, что это существенно повысило производительность, по-прежнему существовали десятки реплик чтения базы данных, которые отставали от основной на несколько часов.
    - 13:15 UTC 22-10-18 фиксируется приближение к пиковой нагрузке трафика на GitHub.com. Группой реагирования приняты новые решения для ускорения репликации.
    - 16:24 UTC 22-10-18 завершение синхронизации реплик, переключение на исходную топологию, начало обработки накопившихся данных из очередей.
    - 16:45 UTC 22-10-18 выполнение балансировки возросшей нагрузки. Увеличено значение TTL для снижения потерь полезных нагрузок. Продолжено восстановление данных, оставшихся в очереди.
    - 23:03 UTC 22-10-18 подтверждена целостность и правильная работа всех систем. Статус сайта обновлен до зеленого.

- Последующие действия
    - Тонкая настройка конфигурации оркестратора, чтобы предотвратить продвижение основных баз данных через региональные границы. Действия оркестратора были настроены так, что уровень приложений не смог поддержать изменение топологии, спровоцированное оркестратором.
    - Переход на новый механизм отчетов о состоянии, который предоставит более полную информацию о том, что работает, а что нет, и в будущем позволит отображать состояние различных компонентов платформы независимо друг от друга.
    - Внедрение поддержки дополнительного резервирования ресурсов на уровне N+1. Цель этой работы — допустить полный отказ одного центра обработки данных без воздействия на пользователя.
    - Занятие более активной позиции в вопросах тестирования инициативных технических решений перед их внедрением.

